<!DOCTYPE html>
<html lang="en-us">

  <head>
  <link href="http://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">

  <!-- Enable responsiveness on mobile devices-->
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

  <title>
    Publications - Zitong Lu
  </title>

  <!-- CSS -->
  <link rel="stylesheet" href="/public/css/poole.css">
  <link rel="stylesheet" href="/public/css/syntax.css">
  <link rel="stylesheet" href="/public/css/hyde.css">
  <link rel="stylesheet" href="http://fonts.googleapis.com/css?family=PT+Sans:400,400italic,700|Abril+Fatface">

  <!-- Icons -->
  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="/public/apple-touch-icon-144-precomposed.png">
                                 <link rel="shortcut icon" href="/public/favicon.ico">

  <!-- RSS -->
  <link rel="alternate" type="application/rss+xml" title="RSS" href="/atom.xml">
</head>


  <body class="theme-base-08">

    <div class="sidebar">
  <div class="container sidebar-sticky">
    <div class="sidebar-about">
      <h1>
        <a href="/" style="font-size: 60px">
          Zitong Lu
        </a>
      </h1>
      <p class="lead" style="font-size: 20px;">To be<br>an experimental psychologist, <br>a cognitive neuroscientist, <br>an AI research scientist.</p>
    </div>

    <nav class="sidebar-nav">
      <a class="sidebar-nav-item" href="/">About</a>

      

      
      
        
          
        
      
        
      
        
          
        
      
        
      
        
          
            <a class="sidebar-nav-item" href="/education/">Education</a>
          
        
      
        
          
            <a class="sidebar-nav-item" href="/research/">Research</a>
          
        
      
        
          
            <a class="sidebar-nav-item active" href="/publications/">Publications</a>
          
        
      
        
          
            <a class="sidebar-nav-item" href="/presentations/">Presentations</a>
          
        
      

      <a class="sidebar-nav-item" href="/files/CV_ZitongLu.pdf">CV</a>
      
    </nav>


    <a class="sidebar-nav-item" href="https://twitter.com/ZitongLu">Twitter</a>
    <a class="sidebar-nav-item" href="https://scholar.google.com/citations?user=bE5VCKsAAAAJ">Google Scholar</a>
    <a class="sidebar-nav-item" href="https://github.com/ZitongLu1996">GitHub</a>
    <a class="sidebar-nav-item" href="https://www.researchgate.net/profile/Zitong-Lu-2">ResearchGate</a>
  </div>
</div>


    <div class="content container">
      <div class="page">
  <h1 class="page-title">Publications</h1>
  <p style="line-height: 16px">
<font size="2.5">Google Scholar: <a href="https://scholar.google.com/citations?hl=en&amp;user=bE5VCKsAAAAJ">https://scholar.google.com/citations?hl=en&amp;user=bE5VCKsAAAAJ</a></font>
<br />
<font size="2.5"><sup>&xi;</sup>: (co-)first author; <sup>&varphi;</sup>: corresponding author</font>
</p>

<p><strong><em>Preprints &amp; Manuscripts submitted or in preparation</em></strong>:</p>
<p class="message" style="font-size: 18px;">

Ran, M<sup>&xi;</sup>., <strong>Lu, Z<sup>&varphi;</sup></strong>., &amp; Golomb, J.D. (in revision). The influence of a moving object’s location on object identity judgements. <strong><em>PsyArXiv</em></strong>. <a href="https://doi.org/10.31234/osf.io/qcrhu">https://doi.org/10.31234/osf.io/qcrhu</a> [<a href="/files/2024Ran_etal_PsyArXiv.pdf">Preprint Pdf</a>]
<br />
<br />
<strong>Lu, Z<sup>&xi;</sup><sup>&varphi;</sup></strong>., &amp; Wang, Y. (under review). Teach CORnet Human fMRI representations for Enhanced Model-Brain Alignment. <strong><em>Arxiv</em></strong>. <a href="https://doi.org/10.48550/arXiv.2407.10414">https://doi.org/10.48550/arXiv.2407.10414</a> [<a href="/files/2024Lu_Arxiv_b.pdf">Preprint Pdf</a>]
<br />
<br />
<strong>Lu, Z<sup>&xi;</sup><sup>&varphi;</sup></strong>., Wang, Y., &amp; Golomb, J.D. (submitted). Achieving more human-brain like vision via human EEG representational alignment. <strong><em>Arxiv</em></strong>. <a href="https://doi.org/10.48550/arXiv.2401.17231">https://doi.org/10.48550/arXiv.2401.17231</a> [<a href="/files/2024Lu_Arxiv_a.pdf">Preprint Pdf</a>]
<br />
<br />
Zhang, M<sup>&xi;</sup>., <strong>Lu, Z</strong>., Zhou, Y., Ma, W., Li, X., Otani, S<sup>&varphi;</sup>., &amp; Wang, Z<sup>&varphi;</sup>. (submitted). Transcultural differences in neural representations of Theory of Mind between Chinese and Japanese. [<a href="/files/2023Zhang_etal.pdf">Pdf</a>]
<br />
<br />
Zhang, M<sup>&xi;</sup>., <strong>Lu, Z<sup>&xi;</sup></strong>., Su, H., Kwok, S.C., Li, X., &amp; Wang, Z<sup>&varphi;</sup>. (submitted). Musical expertise attenuates cross-modal fast-“same” effect of pitches: an ERP study. <strong><em>PsyArXiv</em></strong>. <a href="">https://doi.org/10.31234/osf.io/w74nr</a> [<a href="/files/2022Zhang_PsyArXiv.pdf">Preprint Pdf</a>]
<br />
<br />
Clayson, P.E<sup>&xi;</sup>., …, <strong>Lu, Z</strong>., …, Langer. N. (2023 accepted, stage 1 registered replication). Contralateral delay activity as a marker of visual working memory capacity: a multi-site registered replication. <strong><em>PsyArXiv</em></strong>. <a href="https://psyarxiv.com/shdea/">https://psyarxiv.com/shdea/</a> [<a href="/files/2023Strzelczyk_PsyArXiv.pdf">Preprint Pdf</a>]
<br />
<br />
<strong>Lu, Z<sup>&xi;</sup><sup>&varphi;</sup></strong>., &amp; Golomb, J.D. (in preparation). The influence of task-irrelevant landmarks on spatiotopic localization and object-location binding.
<br />
<br />
<strong>Lu, Z<sup>&xi;</sup><sup>&varphi;</sup></strong>., &amp; Golomb, J.D. (in preparation). Exploring human vision through Img2EEG: An encoding framework generating high-resolution temporal EEG signals from visual inputs.

</p>

<p><strong><em>Peer-reviewed publications</em></strong>:</p>
<p class="message" style="font-size: 18px;">
<br />
<strong>Lu, Z<sup>&xi;</sup><sup>&varphi;</sup></strong>., Wang, Y., &amp; Golomb, J.D. (2024). ReAlnet: Achieving more human-brain like vision via human neural representational alignment. <strong><em>Proceedings of the Conference on Cognitive Computational Neuroscience 2024 (CCN 2024)</em></strong>. [<a href="https://2024.ccneuro.org/pdf/88_Paper_authored_ReAlnet_CCN2024_Authored.pdf">https://2024.ccneuro.org/pdf/88_Paper_authored_ReAlnet_CCN2024_Authored.pdf</a>][<a href="/files/2024Lu_CCN_a.pdf">Pdf</a>]
<br />
<br />
<strong>Lu, Z<sup>&xi;</sup><sup>&varphi;</sup></strong>., &amp; Golomb, J.D. (2024). Probing Human Vision via an Image-to-EEG Encoding Model. <strong><em>Proceedings of the Conference on Cognitive Computational Neuroscience 2024 (CCN 2024)</em></strong>. [<a href="https://2024.ccneuro.org/pdf/337_Paper_authored_Img2EEG_CCN2024_Authored.pdf">https://2024.ccneuro.org/pdf/337_Paper_authored_Img2EEG_CCN2024_Authored.pdf</a>][<a href="/files/2024Lu_CCN_b.pdf">Pdf</a>]
<br />
<br />
<strong>Lu, Z<sup>&xi;</sup><sup>&varphi;</sup></strong>., &amp; Golomb, J.D. (2024 Accepted; Reviewed Preprint). Human EEG and artificial neural networks reveal disentangled representations of object real-world size in natural images. <strong><em>eLife</em></strong>. Preprint online: <a href="https://doi.org/10.7554/eLife.98117.1">https://doi.org/10.7554/eLife.98117.1</a> [<a href="/files/2024Lu_eLife.pdf">Pdf</a>]
<br />
<br />
<strong>Lu, Z<sup>&xi;</sup><sup>&varphi;</sup></strong>., Li, W., Nie, L., &amp; Zhao, K. (2024). An easy-to-follow handbook for electroencephalogram data analysis with Python. <strong><em>Brain-X</em></strong>. e64. <a href="https://doi.org/10.1002/brx2.64">https://doi.org/10.1002/brx2.64</a> [<a href="/files/2024Lu_BrainX.pdf">Pdf</a>]
<br />
<br />
<strong>Lu, Z<sup>&xi;</sup><sup>&varphi;</sup></strong>., &amp; Golomb, J.D<sup>&varphi;</sup>. (2024). Dynamic saccade context triggers more stable object-location binding. <strong><em>Journal of Experimental Psychology: General</em></strong>. 153(4), 873-888. (<strong>APA "Editor's Choice" Paper!</strong>) <a href="https://doi.org/10.1037/xge0001545">https://doi.org/10.1037/xge0001545</a> [<a href="/files/2024Lu_JEPG.pdf">Pdf</a>]
<br />
<br />
<strong>Lu, Z<sup>&xi;</sup></strong>., &amp; Ku, Y<sup>&varphi;</sup>. (2023). Bridging the Gap between EEG and DCNNs Reveals a Fatigue Machanism of Facial Repetition Suppression. <strong><em>iScience</em></strong>. 108501. <a href="https://doi.org/10.1016/j.isci.2023.108501">https://doi.org/10.1016/j.isci.2023.108501</a> [<a href="/files/2023Lu_iScience.pdf">Pdf</a>]
<br />
<br />
<strong>Lu, Z<sup>&xi;</sup><sup>&varphi;</sup></strong>. (2023). Visualizing the Mind’s Eye: A Future Perspective on Applications of Image Reconstruction from Brain Signals to Psychiatry. <strong><em>Psychpradiology</em></strong>. kkad022. <a href="https://doi.org/10.1093/psyrad/kkad022">https://doi.org/10.1093/psyrad/kkad022</a> [<a href="/files/2023Lu_Psyrad.pdf">Pdf</a>]
<br />
<br />
<strong>Lu, Z<sup>&xi;</sup><sup>&varphi;</sup></strong>., &amp; Golomb, J.D. (2023). Object real-world size representations in human brains and artificial neural networks. <strong><em>Proceedings of the Conference on Cognitive Computational Neuroscience 2023 (CCN 2023)</em></strong>. <a href="https://doi.org/10.32470/CCN.2023.1227-0">https://doi.org/10.32470/CCN.2023.1227-0</a> [<a href="https://2023.ccneuro.org/proceedings/0000909.pdf">https://2023.ccneuro.org/proceedings/0000909.pdf</a>][<a href="/files/2023Lu_CCN.pdf">Pdf</a>]
<br />
<br />
<strong>Lu, Z<sup>&xi;</sup><sup>&varphi;</sup></strong>., &amp; Golomb, J.D. (2023). Generate your neural signals from mine: individual-to-individual EEG converters. <strong><em>Proceedings of the 45th Annual Meeting of the Cognitive Science Society (CogSci 2023)</em></strong>. <a href="https://escholarship.org/uc/item/5xn0885t">https://escholarship.org/uc/item/5xn0885t</a> [<a href="/files/2023Lu_CogSci.pdf">Pdf</a>]
<br />
<br />
<strong>Lu, Z<sup>&xi;</sup></strong>., Shafer-Skelton, A., &amp; Golomb, J.D<sup>&varphi;</sup>. (2022). Gaze-centered spatial representations in human hippocampus. <strong><em>Proceedings of the Conference on Cognitive Computational Neuroscience 2022 (CCN 2022)</em></strong>. <a href="https://doi.org/10.32470/CCN.2022.1088-0">https://doi.org/10.32470/CCN.2022.1088-0</a> [<a href="https://2022.ccneuro.org/proceedings/0000614.pdf">https://2022.ccneuro.org/proceedings/0000614.pdf</a>][<a href="/files/2022Lu_CCN.pdf">Pdf</a>]
<br />
<br />
<strong>Lu, Z<sup>&xi;</sup></strong>., &amp; Ku, Y<sup>&varphi;</sup>. (2020). NeuroRA: A Python toolbox of representational analysis from multi-modal neural data. <strong><em>Frontiers in Neuroinformatics</em></strong>. 14:563669. <a href="https://doi.org/10.3389/fninf.2020.563669">https://doi.org/10.3389/fninf.2020.563669</a> [<a href="/files/2021Lu_FININ.pdf">Pdf</a>][<a href="https://zitonglu1996.github.io/NeuroRA/">Link</a>][<a href="https://github.com/ZitongLu1996/NeuroRA">Code</a>]
<br />
<br />
<strong>Lu, Z<sup>&xi;</sup><sup>&varphi;</sup></strong>. (2020). PyCTRSA: A Python package for cross-temporal representational similarity analysis-based E/MEG decoding. <strong><em>Zenodo</em></strong>. <a href="">https://doi.org/10.5281/zenodo.4273674</a> [<a href="https://zenodo.org/record/4273674#.ZBiGNOzMLp4">Link</a>][<a href="https://github.com/ZitongLu1996/PyCTRSA">Code</a>]

</p>

</div>
    </div>

  </body>
</html>
